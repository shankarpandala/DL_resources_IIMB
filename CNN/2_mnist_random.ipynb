{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "## Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "batch_size = 64"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "((60000, 28, 28), (60000,), (10000, 28, 28), (10000,))"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import keras\n",
    "from keras.datasets import mnist\n",
    "(X_train, y_train), (X_test, y_test) = mnist.load_data()\n",
    "(X_train.shape, y_train.shape, X_test.shape, y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((1000, 28, 28), (1000,), (500, 28, 28), (500,))"
      ]
     },
     "execution_count": 90,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    "X_train=X_train[:1000]\n",
    "X_test=X_test[:500]\n",
    "y_train=y_train[:1000]\n",
    "y_test=y_test[:500]\n",
    "(X_train.shape, y_train.shape, X_test.shape, y_test.shape)\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# For flow function x: data. Should have rank as 4. \n",
    "# In case of grayscale data, the channels axis should have value 1, \n",
    "# and in case of RGB data, it should have value 3.\n",
    "\n",
    "X_train = np.expand_dims(X_train,1)\n",
    "X_test = np.expand_dims(X_test,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(60000, 1, 28, 28)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([5, 0, 4, 1, 9], dtype=uint8)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "from keras.utils.np_utils import to_categorical\n",
    "\n",
    "y_train = to_categorical(y_train)\n",
    "y_test = to_categorical(y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0., 0., 0., 0., 0., 1., 0., 0., 0., 0.],\n",
       "       [1., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "       [0., 0., 0., 0., 1., 0., 0., 0., 0., 0.],\n",
       "       [0., 1., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "       [0., 0., 0., 0., 0., 0., 0., 0., 0., 1.]], dtype=float32)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "mean_px = X_train.mean(dtype=np.float32)\n",
    "std_px = X_train.std(dtype=np.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "def norm_input(x):\n",
    "    return (x-mean_px)/std_px"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Importing keras modules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers.core import Lambda, Flatten, Dense \n",
    "from keras.optimizers import Adam"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Pre-processing the images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.preprocessing import image\n",
    "\n",
    "gen = image.ImageDataGenerator()\n",
    "batches = gen.flow(X_train, y_train, batch_size=64)\n",
    "val_batches = gen.flow(X_test, y_test, batch_size=64)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "## NN without hidden layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "nn_without_hidden = Sequential([\n",
    "        Lambda(norm_input, input_shape=(1,28,28)),\n",
    "        Flatten(),\n",
    "        Dense(10, activation='softmax')\n",
    "        ])\n",
    "\n",
    "nn_without_hidden.compile(Adam(), loss='categorical_crossentropy', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/1\n",
      "60000/60000 [==============================] - 234s 4ms/step - loss: 0.2509 - acc: 0.9298 - val_loss: 0.3032 - val_acc: 0.9210\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x22ea88b60b8>"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nn_without_hidden.fit_generator(generator=batches, steps_per_epoch=batches.n, epochs=1, \n",
    "                                validation_data=val_batches, validation_steps=val_batches.n)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "## NN with hidden layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "nn_with_hidden = Sequential([\n",
    "        Lambda(norm_input, input_shape=(1,28,28)),\n",
    "        Flatten(),\n",
    "        Dense(512, activation='tanh'),\n",
    "        Dense(10, activation='softmax')\n",
    "        ])\n",
    "\n",
    "nn_with_hidden.compile(Adam(), loss='categorical_crossentropy', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/1\n",
      "60000/60000 [==============================] - 13s - loss: 1.5433 - acc: 0.8890 - val_loss: 1.0137 - val_acc: 0.9234\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7f30a542a210>"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nn_with_hidden.fit_generator(generator=batches, steps_per_epoch=batches.n, epochs=1, \n",
    "                                validation_data=val_batches, validation_steps=val_batches.n)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "## Adding Convolution Layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.layers import Conv2D,MaxPooling2D"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [],
   "source": [
    "conv_model = Sequential([\n",
    "        Lambda(norm_input, input_shape=(1,28,28)),\n",
    "        Conv2D(32,(3,3), activation='relu'),\n",
    "        Conv2D(32,(3,3), activation='relu'),\n",
    "        MaxPooling2D(),\n",
    "        Conv2D(64,(3,3), activation='relu'),\n",
    "        Conv2D(64,(3,3), activation='relu'),\n",
    "        MaxPooling2D(),\n",
    "        Flatten(),\n",
    "        Dense(512, activation='relu'),\n",
    "        Dense(10, activation='softmax')\n",
    "        ])\n",
    "\n",
    "conv_model.compile(Adam(), loss='categorical_crossentropy', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "lambda_9 (Lambda)            (None, 1, 28, 28)         0         \n",
      "_________________________________________________________________\n",
      "conv2d_7 (Conv2D)            (None, 32, 26, 26)        320       \n",
      "_________________________________________________________________\n",
      "conv2d_8 (Conv2D)            (None, 32, 24, 24)        9248      \n",
      "_________________________________________________________________\n",
      "max_pooling2d_3 (MaxPooling2 (None, 32, 12, 12)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_9 (Conv2D)            (None, 64, 10, 10)        18496     \n",
      "_________________________________________________________________\n",
      "conv2d_10 (Conv2D)           (None, 64, 8, 8)          36928     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_4 (MaxPooling2 (None, 64, 4, 4)          0         \n",
      "_________________________________________________________________\n",
      "flatten_7 (Flatten)          (None, 1024)              0         \n",
      "_________________________________________________________________\n",
      "dense_9 (Dense)              (None, 512)               524800    \n",
      "_________________________________________________________________\n",
      "dense_10 (Dense)             (None, 10)                5130      \n",
      "=================================================================\n",
      "Total params: 594,922\n",
      "Trainable params: 594,922\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "conv_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/1\n",
      "60000/60000 [==============================] - 21s - loss: 0.1093 - acc: 0.9667 - val_loss: 0.0589 - val_acc: 0.9797\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7f309f9afa10>"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "conv_model.fit_generator(generator=batches, steps_per_epoch=batches.n, epochs=1, \n",
    "                                validation_data=val_batches, validation_steps=val_batches.n)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "### Data augmentation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "gen = image.ImageDataGenerator(rotation_range=8, width_shift_range=0.08, shear_range=0.3,\n",
    "                               height_shift_range=0.08, zoom_range=0.08)\n",
    "\n",
    "batches = gen.flow(X_train, y_train, batch_size=64)\n",
    "val_batches = gen.flow(X_test, y_test, batch_size=64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "collapsed": true,
    "hidden": true
   },
   "outputs": [],
   "source": [
    "conv_model.optimizer.lr=0.001"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/8\n",
      "60000/60000 [==============================] - 21s - loss: 0.0583 - acc: 0.9823 - val_loss: 0.0462 - val_acc: 0.9864\n",
      "Epoch 2/8\n",
      "60000/60000 [==============================] - 21s - loss: 0.0467 - acc: 0.9855 - val_loss: 0.0381 - val_acc: 0.9872\n",
      "Epoch 3/8\n",
      "60000/60000 [==============================] - 20s - loss: 0.0417 - acc: 0.9870 - val_loss: 0.0330 - val_acc: 0.9896\n",
      "Epoch 4/8\n",
      "60000/60000 [==============================] - 21s - loss: 0.0390 - acc: 0.9881 - val_loss: 0.0384 - val_acc: 0.9876\n",
      "Epoch 5/8\n",
      "60000/60000 [==============================] - 21s - loss: 0.0361 - acc: 0.9888 - val_loss: 0.0325 - val_acc: 0.9888\n",
      "Epoch 6/8\n",
      "60000/60000 [==============================] - 21s - loss: 0.0335 - acc: 0.9895 - val_loss: 0.0275 - val_acc: 0.9914\n",
      "Epoch 7/8\n",
      "60000/60000 [==============================] - 21s - loss: 0.0310 - acc: 0.9902 - val_loss: 0.0308 - val_acc: 0.9896\n",
      "Epoch 8/8\n",
      "60000/60000 [==============================] - 21s - loss: 0.0302 - acc: 0.9906 - val_loss: 0.0307 - val_acc: 0.9909\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7f30bcda1f10>"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "conv_model.fit_generator(generator=batches, steps_per_epoch=batches.n, epochs=1, \n",
    "                                validation_data=val_batches, validation_steps=val_batches.n)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "np.argmax(conv_model.predict(np.expand_dims(X_test[2],1)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "y_test[2]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "## Adding Batch Normalization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.layers.normalization import BatchNormalization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [],
   "source": [
    "conv_batchnorm = Sequential([\n",
    "        Lambda(norm_input, input_shape=(1,28,28)),\n",
    "        Conv2D(32,(3,3), activation='relu'),\n",
    "        BatchNormalization(axis=1),\n",
    "        Conv2D(32,(3,3), activation='relu'),\n",
    "        MaxPooling2D(),\n",
    "        BatchNormalization(axis=1),\n",
    "        Conv2D(64,(3,3), activation='relu'),\n",
    "        BatchNormalization(axis=1),\n",
    "        Conv2D(64,(3,3), activation='relu'),\n",
    "        MaxPooling2D(),\n",
    "        Flatten(),\n",
    "        BatchNormalization(),\n",
    "        Dense(512, activation='relu'),\n",
    "        BatchNormalization(),\n",
    "        Dense(10, activation='softmax')\n",
    "        ])\n",
    "\n",
    "conv_batchnorm.compile(Adam(), loss='categorical_crossentropy', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "conv_batchnorm.optimizer.lr=0.001"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/12\n",
      "60000/60000 [==============================] - 49s - loss: 0.0346 - acc: 0.9890 - val_loss: 0.0332 - val_acc: 0.9900\n",
      "Epoch 2/12\n",
      "60000/60000 [==============================] - 49s - loss: 0.0361 - acc: 0.9892 - val_loss: 0.0435 - val_acc: 0.9875\n",
      "Epoch 3/12\n",
      "60000/60000 [==============================] - 48s - loss: 0.0339 - acc: 0.9895 - val_loss: 0.0318 - val_acc: 0.9901\n",
      "Epoch 4/12\n",
      "60000/60000 [==============================] - 48s - loss: 0.0309 - acc: 0.9904 - val_loss: 0.0332 - val_acc: 0.9899\n",
      "Epoch 5/12\n",
      "60000/60000 [==============================] - 49s - loss: 0.0304 - acc: 0.9905 - val_loss: 0.0267 - val_acc: 0.9907\n",
      "Epoch 6/12\n",
      "60000/60000 [==============================] - 48s - loss: 0.0299 - acc: 0.9911 - val_loss: 0.0296 - val_acc: 0.9906\n",
      "Epoch 7/12\n",
      "60000/60000 [==============================] - 49s - loss: 0.0268 - acc: 0.9915 - val_loss: 0.0340 - val_acc: 0.9895\n",
      "Epoch 8/12\n",
      "60000/60000 [==============================] - 48s - loss: 0.0278 - acc: 0.9912 - val_loss: 0.0273 - val_acc: 0.9916\n",
      "Epoch 9/12\n",
      "60000/60000 [==============================] - 48s - loss: 0.0260 - acc: 0.9919 - val_loss: 0.0192 - val_acc: 0.9935\n",
      "Epoch 10/12\n",
      "60000/60000 [==============================] - 49s - loss: 0.0246 - acc: 0.9921 - val_loss: 0.0285 - val_acc: 0.9916\n",
      "Epoch 11/12\n",
      "60000/60000 [==============================] - 48s - loss: 0.0248 - acc: 0.9923 - val_loss: 0.0261 - val_acc: 0.9912\n",
      "Epoch 12/12\n",
      "60000/60000 [==============================] - 48s - loss: 0.0241 - acc: 0.9928 - val_loss: 0.0292 - val_acc: 0.9917\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7f30809d4510>"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "conv_batchnorm.fit_generator(generator=batches, steps_per_epoch=batches.n, epochs=12, \n",
    "                                validation_data=val_batches, validation_steps=val_batches.n)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "## Regularization - Dropout"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.layers.core import Dropout"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [],
   "source": [
    "conv_batchnorm_dropout = Sequential([\n",
    "        Lambda(norm_input, input_shape=(1,28,28)),\n",
    "        Conv2D(32,(3,3), activation='relu'),\n",
    "        BatchNormalization(axis=1),\n",
    "        Conv2D(32,(3,3), activation='relu'),\n",
    "        MaxPooling2D(),\n",
    "        BatchNormalization(axis=1),\n",
    "        Conv2D(64,(3,3), activation='relu'),\n",
    "        BatchNormalization(axis=1),\n",
    "        Conv2D(64,(3,3), activation='relu'),\n",
    "        MaxPooling2D(),\n",
    "        Flatten(),\n",
    "        BatchNormalization(),\n",
    "        Dense(512, activation='relu'),\n",
    "        BatchNormalization(),\n",
    "        Dropout(0.5),\n",
    "        Dense(10, activation='softmax')\n",
    "        ])\n",
    "\n",
    "conv_batchnorm_dropout.compile(Adam(), loss='categorical_crossentropy', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "conv_batchnorm_dropout.optimizer.lr=0.001"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {
    "hidden": true,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/1\n",
      "60000/60000 [==============================] - 13s - loss: 0.0186 - acc: 0.9942 - val_loss: 0.0193 - val_acc: 0.9945\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7fa7ce5cf290>"
      ]
     },
     "execution_count": 89,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "conv_batchnorm_dropout.fit_generator(generator=batches, steps_per_epoch=batches.n, epochs=1, \n",
    "                                validation_data=val_batches, validation_steps=val_batches.n)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.6"
  },
  "nav_menu": {},
  "toc": {
   "navigate_menu": true,
   "number_sections": true,
   "sideBar": true,
   "threshold": 6,
   "toc_cell": false,
   "toc_section_display": "block",
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
