{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"Assignment2.ipynb","version":"0.3.2","provenance":[{"file_id":"1p3G6Ezb1Munw7b6dWAeKGWQ3UhcCWz_c","timestamp":1557235608992}],"collapsed_sections":[],"toc_visible":true},"kernelspec":{"name":"python3","display_name":"Python 3"},"accelerator":"GPU"},"cells":[{"cell_type":"markdown","metadata":{"id":"-nJ7YEw_vyjG","colab_type":"text"},"source":["# **Not an ideal network**"]},{"cell_type":"code","metadata":{"id":"kGWv5hBhv2jf","colab_type":"code","outputId":"dfdc12e0-b4d8-4a45-a6bf-236e86891fdd","executionInfo":{"status":"ok","timestamp":1557235820278,"user_tz":-330,"elapsed":10471,"user":{"displayName":"Naveen Bhansali","photoUrl":"https://lh3.googleusercontent.com/-Y2Q2ddjS3gI/AAAAAAAAAAI/AAAAAAAABgw/4ISvrF76rnQ/s64/photo.jpg","userId":"12773479088784731593"}},"colab":{"base_uri":"https://localhost:8080/","height":33}},"source":["# https://keras.io/\n","\n","# Install Keras from python package manager and q is for quiet mode. \n","!pip install -q keras\n","import keras"],"execution_count":0,"outputs":[{"output_type":"stream","text":["Using TensorFlow backend.\n"],"name":"stderr"}]},{"cell_type":"code","metadata":{"id":"wnMlDJQKv4VG","colab_type":"code","colab":{}},"source":["# Importing packages\n","import numpy as np\n","\n","from keras.models import Sequential\n","from keras.layers import Flatten\n","from keras.layers import Convolution2D\n","from keras.utils import np_utils\n","\n","from keras.datasets import mnist"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"8CdSu2lMwB9s","colab_type":"code","outputId":"0bcfa408-58ae-4d96-820a-ddb68d56e500","executionInfo":{"status":"ok","timestamp":1557236139748,"user_tz":-330,"elapsed":1557,"user":{"displayName":"Naveen Bhansali","photoUrl":"https://lh3.googleusercontent.com/-Y2Q2ddjS3gI/AAAAAAAAAAI/AAAAAAAABgw/4ISvrF76rnQ/s64/photo.jpg","userId":"12773479088784731593"}},"colab":{"base_uri":"https://localhost:8080/","height":50}},"source":["# Loading training data in X_train and y_train and testing or validation data \n","# in X_test, y_test.\n","\n","# X variables have the pixel value of the digits and y variables have the digit information.\n","(X_train, y_train), (X_test, y_test) = mnist.load_data()"],"execution_count":0,"outputs":[{"output_type":"stream","text":["Downloading data from https://s3.amazonaws.com/img-datasets/mnist.npz\n","11493376/11490434 [==============================] - 0s 0us/step\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"tLaDf0-rwCmj","colab_type":"code","outputId":"5c865b76-5b10-43e5-ec05-c041216bd44a","executionInfo":{"status":"ok","timestamp":1557236310430,"user_tz":-330,"elapsed":946,"user":{"displayName":"Naveen Bhansali","photoUrl":"https://lh3.googleusercontent.com/-Y2Q2ddjS3gI/AAAAAAAAAAI/AAAAAAAABgw/4ISvrF76rnQ/s64/photo.jpg","userId":"12773479088784731593"}},"colab":{"base_uri":"https://localhost:8080/","height":302}},"source":["# Printing the shape or dimension of X_train. This will help us know the number of images in training data.\n","print (X_train.shape)\n","\n","# Importing plotting package and to display the first image of the training dataset.\n","from matplotlib import pyplot as plt\n","%matplotlib inline\n","plt.imshow(X_train[0])"],"execution_count":0,"outputs":[{"output_type":"stream","text":["(60000, 28, 28)\n"],"name":"stdout"},{"output_type":"execute_result","data":{"text/plain":["<matplotlib.image.AxesImage at 0x7faa387e8710>"]},"metadata":{"tags":[]},"execution_count":13},{"output_type":"display_data","data":{"image/png":"iVBORw0KGgoAAAANSUhEUgAAAP8AAAD8CAYAAAC4nHJkAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n","text/plain":["<Figure size 432x288 with 1 Axes>"]},"metadata":{"tags":[]}}]},{"cell_type":"code","metadata":{"id":"erb11jNwwFwl","colab_type":"code","colab":{}},"source":["# X variable for training and testing is reshaped to 4 dimension from 3 dimension by \n","# adding channel as dimension. In the case of black and white image, channel is 1.\n","X_train = X_train.reshape(X_train.shape[0], 28, 28,1)\n","X_test = X_test.reshape(X_test.shape[0], 28, 28,1)"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"RLK4YDoRwHet","colab_type":"code","colab":{}},"source":["# Normalizing the pixel value between 0 and 1.\n","# Since values range from 0 to 255, dividing it by 255 to get within the value of 0 and 1.\n","\n","X_train = X_train.astype('float32')\n","X_test = X_test.astype('float32')\n","X_train /= 255\n","X_test /= 255"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"JNKLOmhlwJQl","colab_type":"code","outputId":"ddc5d744-26b9-4d90-f7f3-20f9f9861c46","executionInfo":{"status":"ok","timestamp":1557236481127,"user_tz":-330,"elapsed":949,"user":{"displayName":"Naveen Bhansali","photoUrl":"https://lh3.googleusercontent.com/-Y2Q2ddjS3gI/AAAAAAAAAAI/AAAAAAAABgw/4ISvrF76rnQ/s64/photo.jpg","userId":"12773479088784731593"}},"colab":{"base_uri":"https://localhost:8080/","height":33}},"source":["# Displaying the first ten digits\n","y_train[:10]"],"execution_count":0,"outputs":[{"output_type":"execute_result","data":{"text/plain":["array([5, 0, 4, 1, 9, 2, 1, 3, 1, 4], dtype=uint8)"]},"metadata":{"tags":[]},"execution_count":16}]},{"cell_type":"code","metadata":{"id":"YusMJguiwKsM","colab_type":"code","colab":{}},"source":["# Convert 1-dimensional class arrays to 10-dimensional class matrices\n","# This is one-hot encoding,\n","# Converting the y values from digit to binary variable of 10 classes (0-9)\n","# The value is 1 for that particular digit \n","# i.e. digit 5 means column number 6 will be 1 and other columns would be 0.\n","Y_train = np_utils.to_categorical(y_train, 10)\n","Y_test = np_utils.to_categorical(y_test, 10)"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"upxc99AswMW0","colab_type":"code","outputId":"657a9f3d-e0e9-4097-b055-fa5ecfcc9348","executionInfo":{"status":"ok","timestamp":1557236653379,"user_tz":-330,"elapsed":940,"user":{"displayName":"Naveen Bhansali","photoUrl":"https://lh3.googleusercontent.com/-Y2Q2ddjS3gI/AAAAAAAAAAI/AAAAAAAABgw/4ISvrF76rnQ/s64/photo.jpg","userId":"12773479088784731593"}},"colab":{"base_uri":"https://localhost:8080/","height":184}},"source":["# Displaying y_train as one-hot encoded variables.\n","Y_train[:10]"],"execution_count":0,"outputs":[{"output_type":"execute_result","data":{"text/plain":["array([[0., 0., 0., 0., 0., 1., 0., 0., 0., 0.],\n","       [1., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n","       [0., 0., 0., 0., 1., 0., 0., 0., 0., 0.],\n","       [0., 1., 0., 0., 0., 0., 0., 0., 0., 0.],\n","       [0., 0., 0., 0., 0., 0., 0., 0., 0., 1.],\n","       [0., 0., 1., 0., 0., 0., 0., 0., 0., 0.],\n","       [0., 1., 0., 0., 0., 0., 0., 0., 0., 0.],\n","       [0., 0., 0., 1., 0., 0., 0., 0., 0., 0.],\n","       [0., 1., 0., 0., 0., 0., 0., 0., 0., 0.],\n","       [0., 0., 0., 0., 1., 0., 0., 0., 0., 0.]], dtype=float32)"]},"metadata":{"tags":[]},"execution_count":18}]},{"cell_type":"code","metadata":{"id":"irTVUE47wNwr","colab_type":"code","outputId":"7fdb285f-c180-4ebe-ff39-e040d2dc72a3","executionInfo":{"status":"ok","timestamp":1557237654445,"user_tz":-330,"elapsed":1036,"user":{"displayName":"Naveen Bhansali","photoUrl":"https://lh3.googleusercontent.com/-Y2Q2ddjS3gI/AAAAAAAAAAI/AAAAAAAABgw/4ISvrF76rnQ/s64/photo.jpg","userId":"12773479088784731593"}},"colab":{"base_uri":"https://localhost:8080/","height":706}},"source":["# Building the network.\n","# Adding convolution layers (# of filters and filter size), with activation as relu\n","# Flattening the output of the last convolution layer\n","# Applying softmax, to get probability-like value for 10 digit class.\n","\n","from keras.layers import Activation, MaxPooling2D\n","\n","model = Sequential() \n","\n","# Input channel dimension = (28,28,1)\n","# Receptive field = 3\n","model.add(Convolution2D(32, 3, 3, activation='relu', input_shape=(28,28,1)))\n","\n","# Input channel dimension = (26,26,32)\n","# Receptive field = 5\n","model.add(Convolution2D(64, 3, 3, activation='relu'))\n","\n","# Input channel dimension = (24,24,64)\n","# Receptive field = 7\n","model.add(Convolution2D(128, 3, 3, activation='relu'))\n","\n","# Input channel dimension = (22,22,128)\n","# Receptive field = 14\n","model.add(MaxPooling2D(pool_size=(2, 2)))\n","\n","# Input channel dimension = (11,11,128)\n","# Receptive field = 16\n","model.add(Convolution2D(256, 3, 3, activation='relu'))\n","\n","# Input channel dimension = (9,9,256)\n","# Receptive field = 18\n","model.add(Convolution2D(512, 3, 3, activation='relu'))\n","\n","# Input channel dimension = (7,7,512)\n","# Receptive field = 20\n","model.add(Convolution2D(1024, 3, 3, activation='relu'))\n","\n","# Input channel dimension = (5,5,1024)\n","# Receptive field = 22\n","model.add(Convolution2D(2048, 3, 3, activation='relu'))\n","\n","# Input channel dimension = (3,3,2048)\n","# Receptive field = 24\n","model.add(Convolution2D(10, 3, 3, activation='relu'))\n","\n","# Input channel dimension = (1,1,10)\n","# Receptive field = 26\n","model.add(Flatten())\n","\n","model.add(Activation('softmax'))\n","\n","model.summary()"],"execution_count":0,"outputs":[{"output_type":"stream","text":["_________________________________________________________________\n","Layer (type)                 Output Shape              Param #   \n","=================================================================\n","conv2d_17 (Conv2D)           (None, 26, 26, 32)        320       \n","_________________________________________________________________\n","conv2d_18 (Conv2D)           (None, 24, 24, 64)        18496     \n","_________________________________________________________________\n","conv2d_19 (Conv2D)           (None, 22, 22, 128)       73856     \n","_________________________________________________________________\n","max_pooling2d_3 (MaxPooling2 (None, 11, 11, 128)       0         \n","_________________________________________________________________\n","conv2d_20 (Conv2D)           (None, 9, 9, 256)         295168    \n","_________________________________________________________________\n","conv2d_21 (Conv2D)           (None, 7, 7, 512)         1180160   \n","_________________________________________________________________\n","conv2d_22 (Conv2D)           (None, 5, 5, 1024)        4719616   \n","_________________________________________________________________\n","conv2d_23 (Conv2D)           (None, 3, 3, 2048)        18876416  \n","_________________________________________________________________\n","conv2d_24 (Conv2D)           (None, 1, 1, 10)          184330    \n","_________________________________________________________________\n","flatten_3 (Flatten)          (None, 10)                0         \n","_________________________________________________________________\n","activation_3 (Activation)    (None, 10)                0         \n","=================================================================\n","Total params: 25,348,362\n","Trainable params: 25,348,362\n","Non-trainable params: 0\n","_________________________________________________________________\n"],"name":"stdout"},{"output_type":"stream","text":["/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:8: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(32, (3, 3), activation=\"relu\", input_shape=(28, 28, 1...)`\n","  \n","/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:12: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(64, (3, 3), activation=\"relu\")`\n","  if sys.path[0] == '':\n","/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:16: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(128, (3, 3), activation=\"relu\")`\n","  app.launch_new_instance()\n","/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:24: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(256, (3, 3), activation=\"relu\")`\n","/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:28: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(512, (3, 3), activation=\"relu\")`\n","/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:32: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(1024, (3, 3), activation=\"relu\")`\n","/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:36: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(2048, (3, 3), activation=\"relu\")`\n","/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:40: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(10, (3, 3), activation=\"relu\")`\n"],"name":"stderr"}]},{"cell_type":"code","metadata":{"id":"VYZOpRb6yG7_","colab_type":"code","colab":{}},"source":["model.compile(loss='categorical_crossentropy',\n","             optimizer='adam',\n","             metrics=['accuracy'])"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"5O248wVQyMft","colab_type":"code","outputId":"9cd16c0c-6cf4-4a51-cdb0-0f1379525b57","executionInfo":{"status":"ok","timestamp":1557238802910,"user_tz":-330,"elapsed":1135687,"user":{"displayName":"Naveen Bhansali","photoUrl":"https://lh3.googleusercontent.com/-Y2Q2ddjS3gI/AAAAAAAAAAI/AAAAAAAABgw/4ISvrF76rnQ/s64/photo.jpg","userId":"12773479088784731593"}},"colab":{"base_uri":"https://localhost:8080/","height":472}},"source":["model.fit(X_train, Y_train, batch_size=32, nb_epoch=10, verbose=1)"],"execution_count":0,"outputs":[{"output_type":"stream","text":["WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/math_ops.py:3066: to_int32 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n","Instructions for updating:\n","Use tf.cast instead.\n"],"name":"stdout"},{"output_type":"stream","text":["/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:1: UserWarning: The `nb_epoch` argument in `fit` has been renamed `epochs`.\n","  \"\"\"Entry point for launching an IPython kernel.\n"],"name":"stderr"},{"output_type":"stream","text":["Epoch 1/10\n","60000/60000 [==============================] - 118s 2ms/step - loss: 1.9053 - acc: 0.1933\n","Epoch 2/10\n","60000/60000 [==============================] - 113s 2ms/step - loss: 1.9133 - acc: 0.1884\n","Epoch 3/10\n","60000/60000 [==============================] - 113s 2ms/step - loss: 2.3026 - acc: 0.0987\n","Epoch 4/10\n","60000/60000 [==============================] - 113s 2ms/step - loss: 2.3026 - acc: 0.0987\n","Epoch 5/10\n","60000/60000 [==============================] - 113s 2ms/step - loss: 2.3026 - acc: 0.0987\n","Epoch 6/10\n","60000/60000 [==============================] - 113s 2ms/step - loss: 2.3026 - acc: 0.0987\n","Epoch 7/10\n","60000/60000 [==============================] - 113s 2ms/step - loss: 2.3026 - acc: 0.0987\n","Epoch 8/10\n","60000/60000 [==============================] - 113s 2ms/step - loss: 2.3026 - acc: 0.0987\n","Epoch 9/10\n","60000/60000 [==============================] - 113s 2ms/step - loss: 2.3026 - acc: 0.0987\n","Epoch 10/10\n","60000/60000 [==============================] - 113s 2ms/step - loss: 2.3026 - acc: 0.0987\n"],"name":"stdout"},{"output_type":"execute_result","data":{"text/plain":["<keras.callbacks.History at 0x7faa387b4ac8>"]},"metadata":{"tags":[]},"execution_count":23}]},{"cell_type":"code","metadata":{"id":"Sst4KneiyOL5","colab_type":"code","colab":{}},"source":["# Model is evaluated on the testing dataset.\n","score = model.evaluate(X_test, Y_test, verbose=0)"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"CfJiXOKsyj4y","colab_type":"code","outputId":"9a3cdba8-04f8-4ee8-82e3-b145f60c6d33","executionInfo":{"status":"ok","timestamp":1557238822633,"user_tz":-330,"elapsed":925,"user":{"displayName":"Naveen Bhansali","photoUrl":"https://lh3.googleusercontent.com/-Y2Q2ddjS3gI/AAAAAAAAAAI/AAAAAAAABgw/4ISvrF76rnQ/s64/photo.jpg","userId":"12773479088784731593"}},"colab":{"base_uri":"https://localhost:8080/","height":33}},"source":["# The score prints the loss and the test accuracy.\n","print(score)"],"execution_count":0,"outputs":[{"output_type":"stream","text":["[2.3025851249694824, 0.098]\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"1A0imYMLrH2Z","colab_type":"code","outputId":"9209b98b-dc8e-4b6b-edae-ab5687a33c2b","executionInfo":{"status":"ok","timestamp":1557238952662,"user_tz":-330,"elapsed":958,"user":{"displayName":"Naveen Bhansali","photoUrl":"https://lh3.googleusercontent.com/-Y2Q2ddjS3gI/AAAAAAAAAAI/AAAAAAAABgw/4ISvrF76rnQ/s64/photo.jpg","userId":"12773479088784731593"}},"colab":{"base_uri":"https://localhost:8080/","height":33}},"source":["#print(model.metrics_names)"],"execution_count":0,"outputs":[{"output_type":"stream","text":["['loss', 'acc']\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"hwLSXt7nyn_0","colab_type":"code","colab":{}},"source":["# Prediction of the test images.\n","y_pred = model.predict(X_test)"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"WWKKoOKwyppN","colab_type":"code","outputId":"2a7fe5bf-695d-456f-e9b7-da8f19ce9ac8","executionInfo":{"status":"ok","timestamp":1557238834358,"user_tz":-330,"elapsed":993,"user":{"displayName":"Naveen Bhansali","photoUrl":"https://lh3.googleusercontent.com/-Y2Q2ddjS3gI/AAAAAAAAAAI/AAAAAAAABgw/4ISvrF76rnQ/s64/photo.jpg","userId":"12773479088784731593"}},"colab":{"base_uri":"https://localhost:8080/","height":184}},"source":["# Shows the predicted y value from the model - probability of the digit.\n","# Model has not learnt anything as the default probability is 0.1\n","print(y_pred[:9])\n","\n","# Prints the actual digit for y_test dataset.\n","print(y_test[:9])"],"execution_count":0,"outputs":[{"output_type":"stream","text":["[[0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1]\n"," [0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1]\n"," [0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1]\n"," [0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1]\n"," [0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1]\n"," [0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1]\n"," [0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1]\n"," [0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1]\n"," [0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1]]\n","[7 2 1 0 4 1 4 9 5]\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"XMdjVkLwokns","colab_type":"text"},"source":["The issue with the model is that in the last convolutional layer -- the number of filters have reduced drastically from 2048 to 10. So lot of information which was in the 2048 kernels is lost and the last layer has to retain 10 filters, in which all the learnt information cannot be held, hence the accuracy is very low. Those 2048 filter's information has to be properly mixed up so that the relevant information is carried on, using 1* 1 convolution.\n","\n","Besides, that for a simple image of 28*28, a model of 25 million parameters is too big than needed. The number of kernels can be reduced to make a simpler model.\n","\n"]}]}